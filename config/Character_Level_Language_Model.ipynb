{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "57e7d8ecc77b4c30855b6300050701a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09f0a82ab1f144eabf88d460fd9f4faf",
              "IPY_MODEL_1e112f270f99451cb59835df09847ee3",
              "IPY_MODEL_b4c583e178ed443f9a0a4ef0ebfc7e42"
            ],
            "layout": "IPY_MODEL_2e320f1acecd489a91711ab62e857e54"
          }
        },
        "09f0a82ab1f144eabf88d460fd9f4faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6ca735dd9004a3f910766de7d5baa76",
            "placeholder": "​",
            "style": "IPY_MODEL_a6f434f1e5f147efb4d69cff85b502a9",
            "value": "enwik8.py: 100%"
          }
        },
        "1e112f270f99451cb59835df09847ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5d81f90536a4d73a2b2b4dfc47cc9a3",
            "max": 2941,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f34435620cb04872b6c9b07ad7aaac83",
            "value": 2941
          }
        },
        "b4c583e178ed443f9a0a4ef0ebfc7e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4aeed002f194f23918eb3a9b5b92c9a",
            "placeholder": "​",
            "style": "IPY_MODEL_93a2e5c25d0c454fb835c69400154bc8",
            "value": " 2.94k/2.94k [00:00&lt;00:00, 201kB/s]"
          }
        },
        "2e320f1acecd489a91711ab62e857e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ca735dd9004a3f910766de7d5baa76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6f434f1e5f147efb4d69cff85b502a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5d81f90536a4d73a2b2b4dfc47cc9a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f34435620cb04872b6c9b07ad7aaac83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4aeed002f194f23918eb3a9b5b92c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93a2e5c25d0c454fb835c69400154bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a81f680d879244b8a199ae4dac530a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a696dfb2cee14dda9167fc33099c4dbf",
              "IPY_MODEL_e84e5c3353a0458b884f9d8d8a0621f0",
              "IPY_MODEL_b553edf4b695432f8114afc5aee0e0a0"
            ],
            "layout": "IPY_MODEL_ecdc8773a9d4416284ee10067b71d849"
          }
        },
        "a696dfb2cee14dda9167fc33099c4dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6382dca9e3d4eff9fa72fb656192faf",
            "placeholder": "​",
            "style": "IPY_MODEL_ff8aa4bf25c54f27877bd481b9715fe8",
            "value": "README.md: 100%"
          }
        },
        "e84e5c3353a0458b884f9d8d8a0621f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26717c70911640e6a09318d8b29ca68a",
            "max": 4275,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83bd8411f9634e6abdae3d64bd748caf",
            "value": 4275
          }
        },
        "b553edf4b695432f8114afc5aee0e0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08324fb12373492296c4a979f0712fe7",
            "placeholder": "​",
            "style": "IPY_MODEL_c477827423e44cd9be07526cdd2acc15",
            "value": " 4.28k/4.28k [00:00&lt;00:00, 256kB/s]"
          }
        },
        "ecdc8773a9d4416284ee10067b71d849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6382dca9e3d4eff9fa72fb656192faf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff8aa4bf25c54f27877bd481b9715fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26717c70911640e6a09318d8b29ca68a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83bd8411f9634e6abdae3d64bd748caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08324fb12373492296c4a979f0712fe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c477827423e44cd9be07526cdd2acc15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7f70bbba1424d1c8ce121322cf3228f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_812b1095337645fe9afeed409580fb1f",
              "IPY_MODEL_741768f9f626491aa0c53c75d679b0a5",
              "IPY_MODEL_d8f4530aec2f4d20bf2d7dd91812876f"
            ],
            "layout": "IPY_MODEL_cb5328aa45104c90be56ec599c9a0940"
          }
        },
        "812b1095337645fe9afeed409580fb1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2b6f4fad9de4847bd694e4cd5439edd",
            "placeholder": "​",
            "style": "IPY_MODEL_d1d66d38f36f43c19dd0c3389ccb595c",
            "value": "Downloading data: 100%"
          }
        },
        "741768f9f626491aa0c53c75d679b0a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_186fe082019a4215b9123894933bd67b",
            "max": 36445475,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d42306ebb0e54c778578ea61f22bfad8",
            "value": 36445475
          }
        },
        "d8f4530aec2f4d20bf2d7dd91812876f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9a6bf30c57047e99d2595a5f38a10d1",
            "placeholder": "​",
            "style": "IPY_MODEL_6f602f24a5ae47bdb281476d0e32eb1c",
            "value": " 36.4M/36.4M [00:03&lt;00:00, 16.2MB/s]"
          }
        },
        "cb5328aa45104c90be56ec599c9a0940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b6f4fad9de4847bd694e4cd5439edd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1d66d38f36f43c19dd0c3389ccb595c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "186fe082019a4215b9123894933bd67b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d42306ebb0e54c778578ea61f22bfad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9a6bf30c57047e99d2595a5f38a10d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f602f24a5ae47bdb281476d0e32eb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "507bbd3aca6e470aa6a9468e4ce60744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12795bd80b8b46e8a25b2eff591cac81",
              "IPY_MODEL_cd5865dd56cb4c27a98fe4e294657eaf",
              "IPY_MODEL_5ee2f43b46884ceea1b0a123263625b5"
            ],
            "layout": "IPY_MODEL_510d0541c4e749b5876ad16763a4775c"
          }
        },
        "12795bd80b8b46e8a25b2eff591cac81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_297fe391d2894f0e91ca9e1b11add17f",
            "placeholder": "​",
            "style": "IPY_MODEL_84c98cfde6d447cc81166e71fe334697",
            "value": "Generating train split: 100%"
          }
        },
        "cd5865dd56cb4c27a98fe4e294657eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b093c3dc0f9a447380ec4535f6042d17",
            "max": 1128024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8df94b58328e495f99c43f112458cb0c",
            "value": 1128024
          }
        },
        "5ee2f43b46884ceea1b0a123263625b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8e12c660f754df8bb86fd4509f9eba5",
            "placeholder": "​",
            "style": "IPY_MODEL_213ac34f960b4f8985be3cf3f7924ac1",
            "value": " 1128024/1128024 [00:20&lt;00:00, 39392.87 examples/s]"
          }
        },
        "510d0541c4e749b5876ad16763a4775c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "297fe391d2894f0e91ca9e1b11add17f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c98cfde6d447cc81166e71fe334697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b093c3dc0f9a447380ec4535f6042d17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8df94b58328e495f99c43f112458cb0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8e12c660f754df8bb86fd4509f9eba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213ac34f960b4f8985be3cf3f7924ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clone the NanoGPT repository and install necessary dependencies"
      ],
      "metadata": {
        "id": "xaznW94rST2C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5wm4-WVRism",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a304c15-f466-4878-8718-ea2669c47811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nanoGPT'...\n",
            "remote: Enumerating objects: 682, done.\u001b[K\n",
            "remote: Total 682 (delta 0), reused 0 (delta 0), pack-reused 682 (from 1)\u001b[K\n",
            "Receiving objects: 100% (682/682), 952.47 KiB | 17.32 MiB/s, done.\n",
            "Resolving deltas: 100% (385/385), done.\n",
            "/content/nanoGPT\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.14.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.14.0-py2.py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: xxhash, smmap, setproctitle, sentry-sdk, pyarrow, docker-pycreds, dill, tiktoken, multiprocess, gitdb, gitpython, wandb, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 multiprocess-0.70.16 pyarrow-17.0.0 sentry-sdk-2.14.0 setproctitle-1.3.3 smmap-5.0.1 tiktoken-0.7.0 wandb-0.18.1 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Clone the NanoGPT repository\n",
        "!git clone https://github.com/karpathy/nanoGPT.git\n",
        "\n",
        "# Navigate into the nanoGPT directory\n",
        "%cd nanoGPT\n",
        "\n",
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install transformers datasets tiktoken wandb tqdm numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the enwik8 Dataset"
      ],
      "metadata": {
        "id": "gZrZl0sIY6Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the enwik8 dataset\n",
        "dataset = load_dataset(\"LTCB/enwik8\", split=\"train\")\n",
        "\n",
        "# Get the text data\n",
        "text_data = ''.join(dataset['text'])\n",
        "\n",
        "# Total number of characters\n",
        "total_chars = len(text_data)\n",
        "print(f\"Total number of characters: {total_chars}\")\n",
        "\n",
        "# Set the number of characters for the training set\n",
        "num_train_chars = 90_000_000\n",
        "\n",
        "# Ensure we have enough characters for training\n",
        "assert total_chars >= num_train_chars, \"Not enough data for 90 million training characters.\"\n",
        "\n",
        "# Calculate remaining characters for validation and testing\n",
        "remaining_chars = total_chars - num_train_chars\n",
        "\n",
        "# Allocate up to 5 million characters for validation\n",
        "num_valid_chars = min(5_000_000, remaining_chars)\n",
        "\n",
        "# Allocate remaining characters for testing\n",
        "num_test_chars = remaining_chars - num_valid_chars\n",
        "\n",
        "# Extract the splits\n",
        "train_text = text_data[:num_train_chars]\n",
        "valid_text = text_data[num_train_chars:num_train_chars + num_valid_chars]\n",
        "test_text = text_data[num_train_chars + num_valid_chars:]\n",
        "\n",
        "# Save to files\n",
        "with open('train.txt', 'w') as f:\n",
        "    f.write(train_text)\n",
        "with open('valid.txt', 'w') as f:\n",
        "    f.write(valid_text)\n",
        "with open('test.txt', 'w') as f:\n",
        "    f.write(test_text)\n",
        "\n",
        "print(\"Data saved to train.txt, valid.txt, and test.txt\")\n",
        "\n",
        "# Verify sizes\n",
        "print(f\"Training characters: {len(train_text)}\")\n",
        "print(f\"Validation characters: {len(valid_text)}\")\n",
        "print(f\"Test characters: {len(test_text)}\")"
      ],
      "metadata": {
        "id": "8Ye1dSutZDwg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437,
          "referenced_widgets": [
            "57e7d8ecc77b4c30855b6300050701a6",
            "09f0a82ab1f144eabf88d460fd9f4faf",
            "1e112f270f99451cb59835df09847ee3",
            "b4c583e178ed443f9a0a4ef0ebfc7e42",
            "2e320f1acecd489a91711ab62e857e54",
            "f6ca735dd9004a3f910766de7d5baa76",
            "a6f434f1e5f147efb4d69cff85b502a9",
            "b5d81f90536a4d73a2b2b4dfc47cc9a3",
            "f34435620cb04872b6c9b07ad7aaac83",
            "f4aeed002f194f23918eb3a9b5b92c9a",
            "93a2e5c25d0c454fb835c69400154bc8",
            "a81f680d879244b8a199ae4dac530a35",
            "a696dfb2cee14dda9167fc33099c4dbf",
            "e84e5c3353a0458b884f9d8d8a0621f0",
            "b553edf4b695432f8114afc5aee0e0a0",
            "ecdc8773a9d4416284ee10067b71d849",
            "e6382dca9e3d4eff9fa72fb656192faf",
            "ff8aa4bf25c54f27877bd481b9715fe8",
            "26717c70911640e6a09318d8b29ca68a",
            "83bd8411f9634e6abdae3d64bd748caf",
            "08324fb12373492296c4a979f0712fe7",
            "c477827423e44cd9be07526cdd2acc15",
            "b7f70bbba1424d1c8ce121322cf3228f",
            "812b1095337645fe9afeed409580fb1f",
            "741768f9f626491aa0c53c75d679b0a5",
            "d8f4530aec2f4d20bf2d7dd91812876f",
            "cb5328aa45104c90be56ec599c9a0940",
            "f2b6f4fad9de4847bd694e4cd5439edd",
            "d1d66d38f36f43c19dd0c3389ccb595c",
            "186fe082019a4215b9123894933bd67b",
            "d42306ebb0e54c778578ea61f22bfad8",
            "a9a6bf30c57047e99d2595a5f38a10d1",
            "6f602f24a5ae47bdb281476d0e32eb1c",
            "507bbd3aca6e470aa6a9468e4ce60744",
            "12795bd80b8b46e8a25b2eff591cac81",
            "cd5865dd56cb4c27a98fe4e294657eaf",
            "5ee2f43b46884ceea1b0a123263625b5",
            "510d0541c4e749b5876ad16763a4775c",
            "297fe391d2894f0e91ca9e1b11add17f",
            "84c98cfde6d447cc81166e71fe334697",
            "b093c3dc0f9a447380ec4535f6042d17",
            "8df94b58328e495f99c43f112458cb0c",
            "e8e12c660f754df8bb86fd4509f9eba5",
            "213ac34f960b4f8985be3cf3f7924ac1"
          ]
        },
        "outputId": "adad5369-9986-434b-f129-349370e28b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "enwik8.py:   0%|          | 0.00/2.94k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57e7d8ecc77b4c30855b6300050701a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/4.28k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a81f680d879244b8a199ae4dac530a35"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for LTCB/enwik8 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/LTCB/enwik8.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/36.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7f70bbba1424d1c8ce121322cf3228f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1128024 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "507bbd3aca6e470aa6a9468e4ce60744"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 97492430\n",
            "Data saved to train.txt, valid.txt, and test.txt\n",
            "Training characters: 90000000\n",
            "Validation characters: 5000000\n",
            "Test characters: 2492430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the Data for NanoGPT"
      ],
      "metadata": {
        "id": "d_WZIGzpZLy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory for the dataset\n",
        "!mkdir -p data/enwik8\n",
        "\n",
        "# Move the data files into the dataset directory\n",
        "!mv train.txt valid.txt test.txt data/enwik8/"
      ],
      "metadata": {
        "id": "I1PNqu4ovqgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new script called prepare_enwik8.py\n",
        "%%writefile data/prepare_enwik8.py\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Define the data directory\n",
        "data_dir = 'data/enwik8'\n",
        "\n",
        "# Read the text files\n",
        "with open(os.path.join(data_dir, 'train.txt'), 'r', encoding='utf-8') as f:\n",
        "    train_data = f.read()\n",
        "with open(os.path.join(data_dir, 'valid.txt'), 'r', encoding='utf-8') as f:\n",
        "    val_data = f.read()\n",
        "with open(os.path.join(data_dir, 'test.txt'), 'r', encoding='utf-8') as f:\n",
        "    test_data = f.read()\n",
        "\n",
        "# Get all unique characters from the training set\n",
        "chars = sorted(list(set(train_data)))\n",
        "vocab_size = len(chars)\n",
        "print(f\"Unique characters: {vocab_size}\")\n",
        "\n",
        "# Create mappings from characters to integers and vice versa\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "\n",
        "# Save the mappings for later use\n",
        "meta = {\n",
        "    'vocab_size': vocab_size,\n",
        "    'itos': itos,\n",
        "    'stoi': stoi,\n",
        "}\n",
        "with open(os.path.join(data_dir, 'meta.pkl'), 'wb') as f:\n",
        "    pickle.dump(meta, f)\n",
        "\n",
        "# Encode the data and convert to numpy arrays\n",
        "def encode(s):\n",
        "    # Only encode characters that exist in the stoi dictionary\n",
        "    return [stoi[c] for c in s if c in stoi]\n",
        "\n",
        "train_ids = np.array(encode(train_data), dtype=np.uint16)\n",
        "val_ids = np.array(encode(val_data), dtype=np.uint16)\n",
        "test_ids = np.array(encode(test_data), dtype=np.uint16)\n",
        "\n",
        "# Save the encoded data to binary files\n",
        "train_ids.tofile(os.path.join(data_dir, 'train.bin'))\n",
        "val_ids.tofile(os.path.join(data_dir, 'val.bin'))\n",
        "test_ids.tofile(os.path.join(data_dir, 'test.bin'))\n",
        "\n",
        "print(\"Data preparation complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyZbIlP5cR6o",
        "outputId": "0f686134-2730-41c4-c7c4-486467ea1d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data/prepare_enwik8.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python data/prepare_enwik8.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJtrK_Umd0op",
        "outputId": "542df015-1db7-4940-97f9-0c31f0c60d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique characters: 5486\n",
            "Data preparation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config/enwik8_char_modified.py\n",
        "import math\n",
        "\n",
        "# Configuration for the modified model\n",
        "out_dir = 'out-enwik8-char-modified'  # Output directory for model checkpoints and logs\n",
        "eval_interval = 500\n",
        "eval_iters = 200\n",
        "log_interval = 100\n",
        "\n",
        "always_save_checkpoint = True  # Changed to True to ensure we save checkpoints\n",
        "wandb_log = False\n",
        "wandb_project = 'enwik8-char'\n",
        "wandb_run_name = 'gpt2-enwik8-char-modified'\n",
        "\n",
        "dataset = 'enwik8'\n",
        "gradient_accumulation_steps = 1\n",
        "batch_size = 64  # Adjust based on your GPU memory\n",
        "block_size = 256  # Context length\n",
        "\n",
        "# Model parameters\n",
        "n_layer = 10\n",
        "n_head = 8\n",
        "n_embd = 512\n",
        "dropout = 0.1  # Added some dropout for regularization\n",
        "bias = False  # No bias in LayerNorm and Linear layers\n",
        "\n",
        "# Optimization parameters\n",
        "learning_rate = 1e-3\n",
        "max_iters = 5000  # Increased number of iterations for better training\n",
        "lr_decay_iters = 5000\n",
        "min_lr = 1e-4\n",
        "beta1 = 0.9\n",
        "beta2 = 0.99\n",
        "weight_decay = 0.1\n",
        "grad_clip = 1.0\n",
        "decay_lr = True\n",
        "warmup_iters = 100\n",
        "init_from = 'scratch'  # Initialize model from scratch\n",
        "\n",
        "# Use the modified model\n",
        "model_type = 'modified'\n",
        "\n",
        "# System parameters\n",
        "device = 'cuda'  # Use CUDA for training\n",
        "dtype = 'float16'  # Use float16 for faster training\n",
        "compile = False  # Disable compilation for now"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OqXmms1ht-J",
        "outputId": "a03cf56f-b95a-4d84-ab60-24922e0f23da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config/enwik8_char_modified.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_modified.py\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from model import GPTConfig, GPT\n",
        "import inspect\n",
        "\n",
        "class ModifiedGPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.vocab_size is not None\n",
        "        assert config.block_size is not None\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            drop = nn.Dropout(config.dropout),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = nn.LayerNorm(config.n_embd)\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "\n",
        "        # Initialize sinusoidal and learned positional embeddings\n",
        "        self.pos_emb_sin = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))\n",
        "        self.pos_emb_learned = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))\n",
        "        self._init_sin_pos_emb()\n",
        "\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "        # Apply special scaled init to the residual projections, per GPT-2 paper\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
        "\n",
        "        # Report number of parameters\n",
        "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
        "\n",
        "    def get_num_params(self, non_embedding=True):\n",
        "        \"\"\"\n",
        "        Return the number of parameters in the model.\n",
        "        For non-embedding count (default), the position embeddings get subtracted.\n",
        "        The token embeddings would too, except due to the parameter sharing these\n",
        "        params are actually used as weights in the final layer, so we include them.\n",
        "        \"\"\"\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        if non_embedding:\n",
        "            n_params -= self.transformer.wpe.weight.numel()\n",
        "        return n_params\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def _init_sin_pos_emb(self):\n",
        "        \"\"\"Initialize sinusoidal positional embeddings.\"\"\"\n",
        "        position = torch.arange(0, self.config.block_size).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, self.config.n_embd, 2) * (-math.log(10000.0) / self.config.n_embd))\n",
        "        pe = torch.zeros(1, self.config.block_size, self.config.n_embd)\n",
        "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
        "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
        "        with torch.no_grad():\n",
        "            self.pos_emb_sin.copy_(pe)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device).unsqueeze(0) # shape (1, t)\n",
        "\n",
        "        # Token embeddings\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
        "\n",
        "        # Positional embeddings (sinusoidal + learned)\n",
        "        pos_emb = self.pos_emb_sin[:, :t, :] + self.pos_emb_learned[:, :t, :] + self.transformer.wpe(pos)\n",
        "\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            # if we are given some desired targets also calculate the loss\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "        else:\n",
        "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
        "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
        "            loss = None\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def crop_block_size(self, new_block_size):\n",
        "        # Model surgery to decrease the block size if necessary\n",
        "        # e.g. we may load the GPT2 pretrained model checkpoint (block size 1024)\n",
        "        # but want to use a smaller block size for some smaller, simpler model\n",
        "        assert new_block_size <= self.config.block_size\n",
        "        self.config.block_size = new_block_size\n",
        "        self.transformer.wpe.weight = nn.Parameter(self.transformer.wpe.weight[:new_block_size])\n",
        "        for block in self.transformer.h:\n",
        "            if hasattr(block.attn, 'bias'):\n",
        "                block.attn.bias = block.attn.bias[:,:,:new_block_size,:new_block_size]\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type, override_args=None):\n",
        "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
        "        override_args = override_args or {} # default to empty dict\n",
        "        # only dropout can be overridden see more notes below\n",
        "        assert all(k == 'dropout' for k in override_args)\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
        "\n",
        "        # n_layer, n_head and n_embd are determined from model_type\n",
        "        config_args = {\n",
        "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
        "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "        }[model_type]\n",
        "        print(\"forcing vocab_size=50257, block_size=1024, bias=True\")\n",
        "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
        "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
        "        config_args['bias'] = True # always True for GPT model checkpoints\n",
        "        # we can override the dropout rate, if desired\n",
        "        if 'dropout' in override_args:\n",
        "            print(f\"overriding dropout rate to {override_args['dropout']}\")\n",
        "            config_args['dropout'] = override_args['dropout']\n",
        "        # create a from-scratch initialized minGPT model\n",
        "        config = GPTConfig(**config_args)\n",
        "        model = ModifiedGPT(config)\n",
        "        sd = model.state_dict()\n",
        "        sd_keys = sd.keys()\n",
        "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
        "\n",
        "        # init a huggingface/transformers model\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "\n",
        "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
        "        sd_keys_hf = sd_hf.keys()\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
        "        # this means that we have to transpose these weights when we import them\n",
        "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
        "        for k in sd_keys_hf:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                # special treatment for the Conv1D weights we need to transpose\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                # vanilla copy over the other parameters\n",
        "                assert sd_hf[k].shape == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n",
        "        # start with all of the candidate parameters\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        # filter out those that do not require grad\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {'params': decay_params, 'weight_decay': weight_decay},\n",
        "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
        "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
        "        # Create AdamW optimizer and use the fused version if it is available\n",
        "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "        use_fused = fused_available and device_type == 'cuda'\n",
        "        extra_args = dict(fused=True) if use_fused else dict()\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
        "        print(f\"using fused AdamW: {use_fused}\")\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    def estimate_mfu(self, fwdbwd_per_iter, dt):\n",
        "        \"\"\" estimate model flops utilization (MFU) in units of A100 bfloat16 peak FLOPS \"\"\"\n",
        "        # first estimate the number of flops we do per iteration.\n",
        "        # see PaLM paper Appendix B as ref: https://arxiv.org/abs/2204.02311\n",
        "        N = self.get_num_params()\n",
        "        cfg = self.config\n",
        "        L, H, Q, T = cfg.n_layer, cfg.n_head, cfg.n_embd//cfg.n_head, cfg.block_size\n",
        "        flops_per_token = 6*N + 12*L*H*Q*T\n",
        "        flops_per_fwdbwd = flops_per_token * T\n",
        "        flops_per_iter = flops_per_fwdbwd * fwdbwd_per_iter\n",
        "        # express our flops throughput as ratio of A100 bfloat16 peak flops\n",
        "        flops_achieved = flops_per_iter * (1.0/dt) # per second\n",
        "        flops_promised = 312e12 # A100 GPU bfloat16 peak flops is 312 TFLOPS\n",
        "        mfu = flops_achieved / flops_promised\n",
        "        return mfu\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.dropout = config.dropout\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                     .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.attn_dropout(att)\n",
        "        y = att @ v\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
        "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = new_gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "def new_gelu(x):\n",
        "    return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRTkvkQ2h2EG",
        "outputId": "0dec9d4f-0b38-46bb-924c-900627e4cfb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_modified.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile evaluate.py\n",
        "import torch\n",
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import math\n",
        "from model import GPTConfig, GPT\n",
        "from model_modified import ModifiedGPT  # Import your modified model\n",
        "\n",
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            with torch.amp.autocast(device_type=device):  # Updated autocast\n",
        "                logits, loss = model(x, y)\n",
        "            losses.append(loss.item())\n",
        "    return np.mean(losses)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--model_type', type=str, default='gpt', help='Model type: gpt or modified')\n",
        "    parser.add_argument('--dataset', type=str, default='enwik8', help='Dataset name')\n",
        "    parser.add_argument('--checkpoint', type=str, required=True, help='Checkpoint file')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Load the checkpoint\n",
        "    checkpoint = torch.load(args.checkpoint, map_location=device)\n",
        "\n",
        "    # Load the model configuration from the checkpoint\n",
        "    ckpt_config = checkpoint['config']\n",
        "\n",
        "    # Update vocab_size from the dataset's meta.pkl\n",
        "    with open(f\"data/{args.dataset}/meta.pkl\", 'rb') as f:\n",
        "        meta = pickle.load(f)\n",
        "    vocab_size = meta['vocab_size']\n",
        "    ckpt_config['vocab_size'] = vocab_size\n",
        "\n",
        "    # Filter ckpt_config to only include keys that GPTConfig accepts\n",
        "    valid_config_keys = ['n_layer', 'n_head', 'n_embd', 'block_size', 'bias', 'vocab_size', 'dropout']\n",
        "    model_config_kwargs = {k: ckpt_config[k] for k in valid_config_keys if k in ckpt_config}\n",
        "\n",
        "    # Model configuration\n",
        "    model_config = GPTConfig(**model_config_kwargs)\n",
        "\n",
        "    # Instantiate the model\n",
        "    if args.model_type == 'modified' or ckpt_config.get('model_type') == 'modified':\n",
        "        model = ModifiedGPT(model_config)\n",
        "        print(\"Using ModifiedGPT model.\")\n",
        "    else:\n",
        "        model = GPT(model_config)\n",
        "        print(\"Using GPT model.\")\n",
        "\n",
        "    # Load the model state\n",
        "    model.load_state_dict(checkpoint['model'], strict=False)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # Prepare data loader\n",
        "    block_size = ckpt_config['block_size']\n",
        "    batch_size = ckpt_config.get('batch_size', 64)  # Default to 64 if not specified\n",
        "\n",
        "    # Load validation data\n",
        "    val_data = np.memmap(f'data/{args.dataset}/val.bin', dtype=np.uint16, mode='r')\n",
        "    val_data = torch.from_numpy(val_data.astype(np.int64))\n",
        "\n",
        "    # Create sequences of block_size\n",
        "    num_tokens = len(val_data) - 1  # Subtract 1 to prevent index overflow\n",
        "    x_tokens = val_data[:num_tokens]\n",
        "    y_tokens = val_data[1:num_tokens+1]\n",
        "\n",
        "    # Ensure that the number of tokens is a multiple of block_size\n",
        "    num_batches = num_tokens // block_size\n",
        "    x_tokens = x_tokens[:num_batches * block_size]\n",
        "    y_tokens = y_tokens[:num_batches * block_size]\n",
        "\n",
        "    # Reshape into batches\n",
        "    x_batches = x_tokens.view(-1, block_size)\n",
        "    y_batches = y_tokens.view(-1, block_size)\n",
        "\n",
        "    val_dataset = torch.utils.data.TensorDataset(x_batches, y_batches)\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    val_loss = evaluate(model, val_loader, device)\n",
        "    bpc = val_loss / math.log(2)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Bits per character (bpc): {bpc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvPFk1yJh9TP",
        "outputId": "ef3821f4-2b37-4352-85cc-c7501d42f407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --config config/enwik8_char_modified.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4Icf9KyiB5F",
        "outputId": "a9ec4330-eee7-4802-e726-82dc50bf6d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output directory: out-enwik8-char-modified\n",
            "Tokens per iteration will be: 16,384\n",
            "Found vocab_size = 5486 (inside data/enwik8/meta.pkl)\n",
            "number of parameters: 37.36M\n",
            "Using ModifiedGPT model.\n",
            "/content/nanoGPT/train.py:131: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(config['dtype'] == 'float16'))\n",
            "num decayed parameter tensors: 45, with 37,468,160 parameters\n",
            "num non-decayed parameter tensors: 42, with 21,504 parameters\n",
            "using fused AdamW: True\n",
            "Number of parameters: 37.49M\n",
            "Training Progress:   0% 0/5000 [00:00<?, ?it/s]\n",
            "Step 0: train loss 8.6103, val loss 8.6117\n",
            "Saved checkpoint to: out-enwik8-char-modified/ckpt.pt\n",
            "Iter 0: loss 8.6161, time 2211.48ms, mfu -100.00%\n",
            "Training Progress:   2% 100/5000 [02:41<51:34,  1.58it/s]Iter 100: loss 3.4779, time 631.06ms, mfu 2.00%\n",
            "Training Progress:   4% 200/5000 [03:44<50:45,  1.58it/s]Iter 200: loss 3.0020, time 634.25ms, mfu 2.00%\n",
            "Training Progress:   6% 300/5000 [04:47<49:42,  1.58it/s]Iter 300: loss 2.6974, time 634.89ms, mfu 1.99%\n",
            "Training Progress:   8% 400/5000 [05:51<48:36,  1.58it/s]Iter 400: loss 2.5189, time 633.63ms, mfu 1.99%\n",
            "Training Progress:  10% 500/5000 [06:54<47:33,  1.58it/s]\n",
            "Step 500: train loss 2.2962, val loss 2.2960\n",
            "Saved checkpoint to: out-enwik8-char-modified/ckpt.pt\n",
            "Iter 500: loss 2.3378, time 634.26ms, mfu 1.99%\n",
            "Training Progress:  12% 600/5000 [09:37<46:24,  1.58it/s]Iter 600: loss 2.1779, time 632.64ms, mfu 1.99%\n",
            "Training Progress:  14% 700/5000 [10:41<45:28,  1.58it/s]Iter 700: loss 2.0585, time 634.40ms, mfu 1.99%\n",
            "Training Progress:  16% 800/5000 [11:44<44:21,  1.58it/s]Iter 800: loss 1.9172, time 634.51ms, mfu 1.99%\n",
            "Training Progress:  18% 900/5000 [12:48<43:22,  1.58it/s]Iter 900: loss 1.7440, time 633.48ms, mfu 1.99%\n",
            "Training Progress:  20% 1000/5000 [13:51<42:16,  1.58it/s]\n",
            "Step 1000: train loss 1.6526, val loss 1.6403\n",
            "Saved checkpoint to: out-enwik8-char-modified/ckpt.pt\n",
            "Iter 1000: loss 1.6701, time 633.39ms, mfu 1.99%\n",
            "Training Progress:  22% 1100/5000 [16:35<41:05,  1.58it/s]Iter 1100: loss 1.6486, time 631.21ms, mfu 1.99%\n",
            "Training Progress:  24% 1200/5000 [17:38<40:09,  1.58it/s]Iter 1200: loss 1.6062, time 635.38ms, mfu 1.99%\n",
            "Training Progress:  26% 1300/5000 [18:42<39:03,  1.58it/s]Iter 1300: loss 1.5220, time 634.97ms, mfu 1.99%\n",
            "Training Progress:  28% 1400/5000 [19:45<38:02,  1.58it/s]Iter 1400: loss 1.4232, time 633.66ms, mfu 1.99%\n",
            "Training Progress:  30% 1500/5000 [20:49<36:58,  1.58it/s]\n",
            "Step 1500: train loss 1.3639, val loss 1.3535\n",
            "Saved checkpoint to: out-enwik8-char-modified/ckpt.pt\n",
            "Iter 1500: loss 1.4418, time 634.18ms, mfu 1.99%\n",
            "Training Progress:  32% 1600/5000 [23:39<35:47,  1.58it/s]Iter 1600: loss 1.3680, time 631.59ms, mfu 1.99%\n",
            "Training Progress:  34% 1700/5000 [24:42<34:55,  1.58it/s]Iter 1700: loss 1.3628, time 633.93ms, mfu 1.99%\n",
            "Training Progress:  36% 1800/5000 [25:45<33:46,  1.58it/s]Iter 1800: loss 1.3856, time 635.17ms, mfu 1.99%\n",
            "Training Progress:  38% 1900/5000 [26:49<32:45,  1.58it/s]Iter 1900: loss 1.3603, time 634.30ms, mfu 1.99%\n",
            "Training Progress:  40% 2000/5000 [27:52<31:41,  1.58it/s]\n",
            "Step 2000: train loss 1.2751, val loss 1.2692\n",
            "Saved checkpoint to: out-enwik8-char-modified/ckpt.pt\n",
            "Iter 2000: loss 1.3051, time 635.78ms, mfu 1.99%\n",
            "Training Progress:  42% 2100/5000 [30:36<30:34,  1.58it/s]Iter 2100: loss 1.2796, time 632.02ms, mfu 1.99%\n",
            "Training Progress:  44% 2200/5000 [31:39<29:35,  1.58it/s]Iter 2200: loss 1.2886, time 634.22ms, mfu 1.99%\n",
            "Training Progress:  46% 2300/5000 [32:43<28:30,  1.58it/s]Iter 2300: loss 1.3610, time 633.86ms, mfu 1.99%\n",
            "Training Progress:  48% 2400/5000 [33:46<27:27,  1.58it/s]Iter 2400: loss 1.2509, time 632.15ms, mfu 1.99%\n",
            "Training Progress:  50% 2500/5000 [34:49<26:24,  1.58it/s]\n",
            "Step 2500: train loss 1.2153, val loss 1.2120\n",
            "Saved checkpoint to: out-enwik8-char-modified/ckpt.pt\n",
            "Iter 2500: loss 1.2918, time 633.82ms, mfu 1.99%\n",
            "Training Progress:  52% 2600/5000 [37:38<25:16,  1.58it/s]Iter 2600: loss 1.3075, time 630.31ms, mfu 1.99%\n",
            "Training Progress:  54% 2700/5000 [38:42<24:19,  1.58it/s]Iter 2700: loss 1.2795, time 634.98ms, mfu 1.99%\n",
            "Training Progress:  56% 2800/5000 [39:45<23:15,  1.58it/s]Iter 2800: loss 1.2099, time 633.97ms, mfu 1.99%\n",
            "Training Progress:  58% 2900/5000 [40:49<22:11,  1.58it/s]Iter 2900: loss 1.2207, time 635.33ms, mfu 1.99%\n",
            "Training Progress:  60% 3000/5000 [41:52<21:07,  1.58it/s]\n",
            "Step 3000: train loss 1.1803, val loss 1.1735\n",
            "Saved checkpoint to: out-enwik8-char-modified/ckpt.pt\n",
            "Iter 3000: loss 1.1817, time 634.82ms, mfu 1.99%\n",
            "Training Progress:  62% 3100/5000 [44:37<20:01,  1.58it/s]Iter 3100: loss 1.2107, time 631.50ms, mfu 1.99%\n",
            "Training Progress:  64% 3200/5000 [45:40<19:02,  1.58it/s]Iter 3200: loss 1.2201, time 633.38ms, mfu 1.99%\n",
            "Training Progress:  66% 3300/5000 [46:44<17:57,  1.58it/s]Iter 3300: loss 1.2752, time 633.56ms, mfu 1.99%\n",
            "Training Progress:  68% 3400/5000 [47:47<16:53,  1.58it/s]Iter 3400: loss 1.2232, time 633.41ms, mfu 1.99%\n",
            "Training Progress:  70% 3500/5000 [48:51<15:50,  1.58it/s]\n",
            "Step 3500: train loss 1.1516, val loss 1.1477\n",
            "Saved checkpoint to: out-enwik8-char-modified/ckpt.pt\n",
            "Iter 3500: loss 1.1904, time 633.41ms, mfu 1.99%\n",
            "Training Progress:  72% 3600/5000 [51:35<14:45,  1.58it/s]Iter 3600: loss 1.1908, time 633.42ms, mfu 1.99%\n",
            "Training Progress:  74% 3700/5000 [52:38<13:44,  1.58it/s]Iter 3700: loss 1.0857, time 634.79ms, mfu 1.99%\n",
            "Training Progress:  76% 3800/5000 [53:42<12:40,  1.58it/s]Iter 3800: loss 1.2409, time 634.15ms, mfu 1.99%\n",
            "Training Progress:  78% 3900/5000 [54:45<11:37,  1.58it/s]Iter 3900: loss 1.1306, time 634.92ms, mfu 1.99%\n",
            "Training Progress:  80% 4000/5000 [55:49<10:34,  1.58it/s]\n",
            "Step 4000: train loss 1.1258, val loss 1.1198\n",
            "Saved checkpoint to: out-enwik8-char-modified/ckpt.pt\n",
            "Iter 4000: loss 1.1475, time 633.96ms, mfu 1.99%\n",
            "Training Progress:  82% 4100/5000 [58:33<09:29,  1.58it/s]Iter 4100: loss 1.2003, time 632.27ms, mfu 1.99%\n",
            "Training Progress:  84% 4200/5000 [59:36<08:27,  1.58it/s]Iter 4200: loss 1.1469, time 634.70ms, mfu 1.99%\n",
            "Training Progress:  86% 4300/5000 [1:00:40<07:23,  1.58it/s]Iter 4300: loss 1.1841, time 634.96ms, mfu 1.99%\n",
            "Training Progress:  88% 4400/5000 [1:01:43<06:20,  1.58it/s]Iter 4400: loss 1.1625, time 633.08ms, mfu 1.99%\n",
            "Training Progress:  90% 4500/5000 [1:02:46<05:17,  1.58it/s]\n",
            "Step 4500: train loss 1.1114, val loss 1.1072\n",
            "Saved checkpoint to: out-enwik8-char-modified/ckpt.pt\n",
            "Iter 4500: loss 1.1716, time 635.49ms, mfu 1.99%\n",
            "Training Progress:  92% 4600/5000 [1:05:36<04:12,  1.58it/s]Iter 4600: loss 1.1839, time 630.95ms, mfu 1.99%\n",
            "Training Progress:  94% 4700/5000 [1:06:40<03:10,  1.57it/s]Iter 4700: loss 1.1456, time 635.38ms, mfu 1.99%\n",
            "Training Progress:  96% 4800/5000 [1:07:43<02:06,  1.58it/s]Iter 4800: loss 1.1434, time 633.54ms, mfu 1.99%\n",
            "Training Progress:  98% 4900/5000 [1:08:46<01:03,  1.58it/s]Iter 4900: loss 1.1275, time 634.16ms, mfu 1.99%\n",
            "Training Progress: 100% 5000/5000 [1:09:50<00:00,  1.19it/s]\n",
            "Saved final checkpoint to: out-enwik8-char-modified/final_ckpt.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the Baseline Model"
      ],
      "metadata": {
        "id": "bZ_vUsudhEC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# config/enwik8_char_baseline.py\n",
        "%%writefile config/enwik8_char_baseline.py\n",
        "out_dir = 'out-enwik8-char'\n",
        "eval_interval = 500\n",
        "eval_iters = 200\n",
        "log_interval = 100\n",
        "\n",
        "always_save_checkpoint = True\n",
        "wandb_log = False\n",
        "wandb_project = 'enwik8-char'\n",
        "wandb_run_name = 'gpt2-enwik8-char-baseline'\n",
        "\n",
        "dataset = 'enwik8'\n",
        "gradient_accumulation_steps = 1\n",
        "batch_size = 64\n",
        "block_size = 256\n",
        "\n",
        "n_layer = 12\n",
        "n_head = 8\n",
        "n_embd = 384\n",
        "dropout = 0.1\n",
        "bias = False\n",
        "\n",
        "learning_rate = 5e-4\n",
        "max_iters = 5000\n",
        "lr_decay_iters = 5000\n",
        "min_lr = 1e-5\n",
        "beta1 = 0.9\n",
        "beta2 = 0.95\n",
        "weight_decay = 0.1\n",
        "grad_clip = 1.0\n",
        "decay_lr = True\n",
        "warmup_iters = 100\n",
        "init_from = 'scratch'\n",
        "\n",
        "device = 'cuda'\n",
        "dtype = 'float16'\n",
        "compile = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViMsF1NUq2W8",
        "outputId": "9bc6fa5b-55eb-4a05-d2af-5baf2a708c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing config/enwik8_char_baseline.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --config config/enwik8_char_baseline.py"
      ],
      "metadata": {
        "id": "VtfZ2kasZRP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0611ccb-6860-4470-e5d9-11c3a16189f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output directory: out-enwik8-char\n",
            "Tokens per iteration will be: 16,384\n",
            "Found vocab_size = 5486 (inside data/enwik8/meta.pkl)\n",
            "number of parameters: 23.35M\n",
            "Using GPT model.\n",
            "/content/nanoGPT/train.py:131: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(config['dtype'] == 'float16'))\n",
            "num decayed parameter tensors: 50, with 23,438,592 parameters\n",
            "num non-decayed parameter tensors: 25, with 9,600 parameters\n",
            "using fused AdamW: True\n",
            "Number of parameters: 23.45M\n",
            "Training Progress:   0% 0/5000 [00:00<?, ?it/s]\n",
            "Step 0: train loss 8.5904, val loss 8.5955\n",
            "Saved checkpoint to: out-enwik8-char/ckpt.pt\n",
            "Iter 0: loss 8.6010, time 1576.30ms, mfu -100.00%\n",
            "Training Progress:   2% 100/5000 [00:54<19:04,  4.28it/s]Iter 100: loss 2.6764, time 234.54ms, mfu 3.45%\n",
            "Training Progress:   4% 200/5000 [01:18<19:00,  4.21it/s]Iter 200: loss 2.4852, time 242.10ms, mfu 3.44%\n",
            "Training Progress:   6% 300/5000 [01:42<19:20,  4.05it/s]Iter 300: loss 2.2668, time 248.20ms, mfu 3.42%\n",
            "Training Progress:   8% 400/5000 [02:07<19:10,  4.00it/s]Iter 400: loss 2.1443, time 247.64ms, mfu 3.41%\n",
            "Training Progress:  10% 500/5000 [02:32<19:09,  3.91it/s]\n",
            "Step 500: train loss 1.9296, val loss 1.9195\n",
            "Saved checkpoint to: out-enwik8-char/ckpt.pt\n",
            "Iter 500: loss 2.0529, time 253.98ms, mfu 3.39%\n",
            "Training Progress:  12% 600/5000 [03:35<19:01,  3.85it/s]Iter 600: loss 1.8159, time 255.35ms, mfu 3.37%\n",
            "Training Progress:  14% 700/5000 [04:01<18:05,  3.96it/s]Iter 700: loss 1.7610, time 253.69ms, mfu 3.35%\n",
            "Training Progress:  16% 800/5000 [04:26<17:39,  3.97it/s]Iter 800: loss 1.7200, time 251.03ms, mfu 3.34%\n",
            "Training Progress:  18% 900/5000 [04:51<17:19,  3.94it/s]Iter 900: loss 1.5929, time 254.36ms, mfu 3.32%\n",
            "Training Progress:  20% 1000/5000 [05:17<17:01,  3.92it/s]\n",
            "Step 1000: train loss 1.5183, val loss 1.5102\n",
            "Saved checkpoint to: out-enwik8-char/ckpt.pt\n",
            "Iter 1000: loss 1.5249, time 252.28ms, mfu 3.31%\n",
            "Training Progress:  22% 1100/5000 [06:21<16:51,  3.85it/s]Iter 1100: loss 1.5065, time 254.32ms, mfu 3.30%\n",
            "Training Progress:  24% 1200/5000 [06:47<16:06,  3.93it/s]Iter 1200: loss 1.4626, time 257.15ms, mfu 3.28%\n",
            "Training Progress:  26% 1300/5000 [07:12<15:31,  3.97it/s]Iter 1300: loss 1.5030, time 252.19ms, mfu 3.28%\n",
            "Training Progress:  28% 1400/5000 [07:37<15:10,  3.95it/s]Iter 1400: loss 1.4232, time 254.19ms, mfu 3.27%\n",
            "Training Progress:  30% 1500/5000 [08:03<14:58,  3.89it/s]Saved checkpoint to: out-enwik8-char/ckpt.pt\n",
            "Iter 1500: loss 1.4130, time 255.52ms, mfu 3.26%\n",
            "Training Progress:  32% 1600/5000 [09:07<14:44,  3.85it/s]Iter 1600: loss 1.3901, time 262.46ms, mfu 3.24%\n",
            "Training Progress:  34% 1700/5000 [09:33<14:03,  3.91it/s]Iter 1700: loss 1.3171, time 258.15ms, mfu 3.23%\n",
            "Training Progress:  36% 1800/5000 [09:58<13:32,  3.94it/s]Iter 1800: loss 1.2947, time 253.26ms, mfu 3.23%\n",
            "Training Progress:  38% 1900/5000 [10:23<13:02,  3.96it/s]Iter 1900: loss 1.2963, time 256.51ms, mfu 3.22%\n",
            "Training Progress:  40% 2000/5000 [10:49<12:39,  3.95it/s]\n",
            "Step 2000: train loss 1.2735, val loss 1.2600\n",
            "Saved checkpoint to: out-enwik8-char/ckpt.pt\n",
            "Iter 2000: loss 1.3499, time 252.26ms, mfu 3.22%\n",
            "Training Progress:  42% 2100/5000 [11:53<12:36,  3.83it/s]Iter 2100: loss 1.2819, time 264.51ms, mfu 3.20%\n",
            "Training Progress:  44% 2200/5000 [12:18<11:46,  3.96it/s]Iter 2200: loss 1.2849, time 256.31ms, mfu 3.20%\n",
            "Training Progress:  46% 2300/5000 [12:44<11:23,  3.95it/s]Iter 2300: loss 1.2657, time 251.50ms, mfu 3.20%\n",
            "Training Progress:  48% 2400/5000 [13:09<11:02,  3.93it/s]Iter 2400: loss 1.2446, time 253.36ms, mfu 3.20%\n",
            "Training Progress:  50% 2500/5000 [13:35<10:36,  3.93it/s]\n",
            "Step 2500: train loss 1.2192, val loss 1.2070\n",
            "Saved checkpoint to: out-enwik8-char/ckpt.pt\n",
            "Iter 2500: loss 1.2908, time 254.04ms, mfu 3.20%\n",
            "Training Progress:  52% 2600/5000 [14:33<10:09,  3.94it/s]Iter 2600: loss 1.2002, time 254.68ms, mfu 3.20%\n",
            "Training Progress:  54% 2700/5000 [14:58<09:41,  3.96it/s]Iter 2700: loss 1.2744, time 252.08ms, mfu 3.20%\n",
            "Training Progress:  56% 2800/5000 [15:24<09:19,  3.93it/s]Iter 2800: loss 1.2151, time 253.89ms, mfu 3.20%\n",
            "Training Progress:  58% 2900/5000 [15:49<08:52,  3.94it/s]Iter 2900: loss 1.2443, time 254.11ms, mfu 3.20%\n",
            "Training Progress:  60% 3000/5000 [16:15<08:31,  3.91it/s]\n",
            "Step 3000: train loss 1.1761, val loss 1.1699\n",
            "Saved checkpoint to: out-enwik8-char/ckpt.pt\n",
            "Iter 3000: loss 1.2036, time 251.83ms, mfu 3.20%\n",
            "Training Progress:  62% 3100/5000 [17:19<08:18,  3.81it/s]Iter 3100: loss 1.2584, time 262.43ms, mfu 3.19%\n",
            "Training Progress:  64% 3200/5000 [17:44<07:38,  3.93it/s]Iter 3200: loss 1.1857, time 252.25ms, mfu 3.19%\n",
            "Training Progress:  66% 3300/5000 [18:10<07:11,  3.94it/s]Iter 3300: loss 1.2580, time 248.83ms, mfu 3.20%\n",
            "Training Progress:  68% 3400/5000 [18:35<06:49,  3.91it/s]Iter 3400: loss 1.2154, time 253.98ms, mfu 3.20%\n",
            "Training Progress:  70% 3500/5000 [19:00<06:19,  3.95it/s]\n",
            "Step 3500: train loss 1.1557, val loss 1.1521\n",
            "Saved checkpoint to: out-enwik8-char/ckpt.pt\n",
            "Iter 3500: loss 1.1681, time 254.10ms, mfu 3.20%\n",
            "Training Progress:  72% 3600/5000 [20:04<06:04,  3.84it/s]Iter 3600: loss 1.1534, time 258.09ms, mfu 3.19%\n",
            "Training Progress:  74% 3700/5000 [20:30<05:29,  3.95it/s]Iter 3700: loss 1.2070, time 252.18ms, mfu 3.19%\n",
            "Training Progress:  76% 3800/5000 [20:55<05:02,  3.97it/s]Iter 3800: loss 1.1837, time 254.32ms, mfu 3.19%\n",
            "Training Progress:  78% 3900/5000 [21:21<04:40,  3.92it/s]Iter 3900: loss 1.1801, time 256.77ms, mfu 3.19%\n",
            "Training Progress:  80% 4000/5000 [21:46<04:12,  3.95it/s]\n",
            "Step 4000: train loss 1.1364, val loss 1.1296\n",
            "Saved checkpoint to: out-enwik8-char/ckpt.pt\n",
            "Iter 4000: loss 1.1622, time 252.84ms, mfu 3.19%\n",
            "Training Progress:  82% 4100/5000 [22:50<03:55,  3.82it/s]Iter 4100: loss 1.1206, time 258.13ms, mfu 3.18%\n",
            "Training Progress:  84% 4200/5000 [23:16<03:23,  3.93it/s]Iter 4200: loss 1.1558, time 255.44ms, mfu 3.18%\n",
            "Training Progress:  86% 4300/5000 [23:42<02:56,  3.96it/s]Iter 4300: loss 1.1621, time 251.70ms, mfu 3.19%\n",
            "Training Progress:  88% 4400/5000 [24:07<02:33,  3.92it/s]Iter 4400: loss 1.1808, time 257.82ms, mfu 3.18%\n",
            "Training Progress:  90% 4500/5000 [24:33<02:07,  3.91it/s]\n",
            "Step 4500: train loss 1.1221, val loss 1.1203\n",
            "Saved checkpoint to: out-enwik8-char/ckpt.pt\n",
            "Iter 4500: loss 1.1323, time 255.45ms, mfu 3.18%\n",
            "Training Progress:  92% 4600/5000 [25:38<01:44,  3.84it/s]Iter 4600: loss 1.1121, time 260.08ms, mfu 3.17%\n",
            "Training Progress:  94% 4700/5000 [26:04<01:16,  3.93it/s]Iter 4700: loss 1.2230, time 256.54ms, mfu 3.17%\n",
            "Training Progress:  96% 4800/5000 [26:29<00:50,  3.98it/s]Iter 4800: loss 1.1912, time 254.07ms, mfu 3.17%\n",
            "Training Progress:  98% 4900/5000 [26:55<00:25,  3.93it/s]Iter 4900: loss 1.1427, time 260.72ms, mfu 3.17%\n",
            "Training Progress: 100% 5000/5000 [27:20<00:00,  3.05it/s]\n",
            "Saved final checkpoint to: out-enwik8-char/final_ckpt.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/enwik8/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLgFUKqRjNYJ",
        "outputId": "ad590c05-6c0f-47e0-8462-888663f9f9aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meta.pkl  test.bin  test.txt  train.bin  train.txt  val.bin  valid.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evaluate base model"
      ],
      "metadata": {
        "id": "xVuEx03-5cC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py --model_type gpt --checkpoint out-enwik8-char/ckpt.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuzLnYSzrKSe",
        "outputId": "0df05c2b-da9d-4871-ff5f-ffefed7d728c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nanoGPT/evaluate.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(args.checkpoint, map_location=device)\n",
            "number of parameters: 23.35M\n",
            "Using GPT model.\n",
            "Validation Loss: 1.1195, Bits per character (bpc): 1.6151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evaluate modified model"
      ],
      "metadata": {
        "id": "oYjwfvvz5eiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py --model_type modified --checkpoint out-enwik8-char-modified/final_ckpt.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3FaMaa1-CEp",
        "outputId": "f7b5a6ab-9168-4987-bf3a-2d6de0d93aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nanoGPT/evaluate.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(args.checkpoint, map_location=device)\n",
            "number of parameters: 37.36M\n",
            "Using ModifiedGPT model.\n",
            "Validation Loss: 1.1037, Bits per character (bpc): 1.5923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5dQFpaSrKNH",
        "outputId": "12d1a5b2-8834-459b-b79a-5bb89be22baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Data for the table\n",
        "data = [\n",
        "    [\"Number of Parameters\", \"23.35M\", \"37.36M\"],\n",
        "    [\"Validation Loss\", \"1.1195\", \"1.1037\"],\n",
        "    [\"Bits per Character (BPC)\", \"1.6151\", \"1.5923\"]\n",
        "]\n",
        "\n",
        "# Create the table\n",
        "headers = [\"Metric\", \"Baseline Model (GPT)\", \"Modified Model (ModifiedGPT)\"]\n",
        "table = tabulate(data, headers, tablefmt=\"pipe\")\n",
        "\n",
        "# Print the table\n",
        "print(table)\n",
        "\n",
        "# Calculate and print the differences\n",
        "param_diff = 37.36 - 23.35\n",
        "loss_diff = 1.1037 - 1.1195\n",
        "bpc_diff = 1.5923 - 1.6151\n",
        "\n",
        "print(\"\\nDifferences (Modified - Baseline):\")\n",
        "print(f\"Parameter Increase: {param_diff:.2f}M ({param_diff/23.35*100:.2f}% increase)\")\n",
        "print(f\"Validation Loss Improvement: {-loss_diff:.4f}\")\n",
        "print(f\"BPC Improvement: {-bpc_diff:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkP3ZjIXrKK0",
        "outputId": "39238ebd-1432-4e80-89a7-d73f91d6abf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Metric                   | Baseline Model (GPT)   | Modified Model (ModifiedGPT)   |\n",
            "|:-------------------------|:-----------------------|:-------------------------------|\n",
            "| Number of Parameters     | 23.35M                 | 37.36M                         |\n",
            "| Validation Loss          | 1.1195                 | 1.1037                         |\n",
            "| Bits per Character (BPC) | 1.6151                 | 1.5923                         |\n",
            "\n",
            "Differences (Modified - Baseline):\n",
            "Parameter Increase: 14.01M (60.00% increase)\n",
            "Validation Loss Improvement: 0.0158\n",
            "BPC Improvement: 0.0228\n"
          ]
        }
      ]
    }
  ]
}